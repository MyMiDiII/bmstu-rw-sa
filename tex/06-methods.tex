\chapter{Описание существующих решений}

\section{Лингвистический подход}

Методы использующие лингвистический подход можно разделить на три основные
категории:
\begin{itemize}
    \item методы на основе правил;
    \item методы на основе словарей;
    \item методы на основе корпусов.
\end{itemize}

Подход на основе лексикона: В этом подходе, при использовании доступных методов
лексикона для данного текста, происходит разделение слов. В общем случае это
происходит путем агрегирования оценок: например, субъективные оценки слов как
положительные, отрицательные и нейтральные и т.д. суммируются отдельно для
одного и того же слова. Каждому слову присваивается балл. По крайней мере,
четыре балла генерируются. Та, которая набирает максимальное количество баллов,
дает общее разделение текста[10]. В основном он делится на две а) на основе
словаря б) на основе корпуса. \cite{article18}

\subsection{Методы, основанные на правилах}

Работа \textbf{методов на основе правил} реализуется с помощью большого набора
созданных в ручную правил конструкции "если $\rightarrow$ то" \cite{article14}.

Данные алгоритмы имеют отличную производительность в узких
областях тем текстов, однако их обобщение на более широкий круг тем
затруднительно. Также процесс создания необходимых правил является
трудоемким за счет их определения человеком, а не компьютером \cite{article15}.

В целях ускорения процесса разработки для создания набора правил может
использоваться машинное обучение, поэтому в некоторых научных работах
\cite{article16} \cite{article17} данные методы относят к методам машинного
обучения.

Подход на основе правил RB: в котором набор правил используется для
моделирования пространства данных. Левая сторона показывает набор признаков,
выраженных контрапунктическим способом, а правая сторона - метку класса. Условия
основаны на понятии присутствия; отсутствие используется редко, поскольку оно
неинформативно в разреженных данных. Наиболее распространенными критериями,
используемыми при формировании правил, являются поддержка и уверенность [81].
Поддержка - это количество всех примеров в обучающем наборе данных, которые
относятся к правилу. Доверие - это условная вероятность того, что правая часть
правила будет выполнена, если выполнена левая часть [82]. RB используется
примерно в 8 из 157 (около 5\%) исследованных статей. Здесь RB является
единственным подходом для SC в статьях [83], [84]. В большинстве случаев лучшая
производительность достигается при использовании в ансамбле классификаторов или
в сочетании с другим классификатором, как RB+LB в [65]. Объединение RB с CNN в
английском ABSA в [85] позволило получить Pr 79.25\%, R 88.45\%, F1 83.24\%, и
Acc 87\% в обзорах ноутбуков.[86]ансамбль (RB, NB, SVM, и RNTN) достигает оценки
F в 94,49\%. \cite{article2}

В классификаторах, основанных на правилах, пространство данных моделируется с
помощью набора правил. Левая часть представляет собой условие в наборе
характеристик, выраженное в нормальной дизъюнктивной форме, а правая часть -
метку класса. Условия заключаются в наличии термина. Отсутствие термина
используется редко, поскольку оно неинформативно в скудных данных. [8]
Предлагается основанный на правилах подход к обнаружению компонентов причин
эмоций для китайских микроблогов. Представляет модель эмоций и извлекает
соответствующие компоненты причин в мелкозернистых эмоциях. Эмоциональный
лексикон может быть создан вручную и автоматически из корпуса. Между тем,
пропорции причинных компонентов могут быть вычислены на основе многоязычных
характеристик, основанных на Байесовской вероятности. На сайте Результаты
эксперимента показывают осуществимость данного подхода. \cite{article4}

Ассоциативное обучение - это основанные на правилах методы машинного обучения,
которые направлены на исследование связей и зависимостей между определенными
атрибутами данных. В SA подходы на основе правил применялись в основном в
процессе извлечения продукта для улучшения классификации полярности отзывов, как
в Yang and Shih (2012). \cite{article13}

Классификатор на основе правил. Модель, создаваемая классификатором на основе
правил, имеет вид набора правил. На основе этих правил осуществляется
прогнозирование новой информации. Правила всегда имеют форму антецедента и
последователя. IF (антецедент) в левой части представляет условия, а правая
часть (последействие) представляет предсказание класса. Форма правила может быть
представлена ниже [19].
%{w1 /\w2 /\w3 } → {+|-}
Слово в правиле выражает настроение, показанное ниже.
{Good} → {+} {Bad} → {-}
В классификации текста IF часть представляет набор признаков, которые могут быть
присутствием термина, а THEN часть представляет метку. Классификатор на основе
правил использует два термина для определения правила: Доверие и Поддержка.
Количество экземпляров в обучающем наборе данных, связанных с правилом,
определяется поддержкой. Условная вероятность метки, если набор признаков
встречается, представлена доверием в правиле.  Buddeewong и Kreesuradej [20]
предложили алгоритм классификатора текстов на основе ассоциативных правил
(ARTC). В своей работе он создал два набора элементов: Один для тех слов которые
не пересекаются с другими классами, а другой - для тех, которые пересекаются с
другими классами. Затем с помощью наборов частых элементов он создал правила. Он
использовал алгоритм Apriori для генерации правил. В результате эксперимента он
получил 95,08\% точности.  \cite{article16}

4. Классификатор на основе правил - это классификатор на основе условий, который
использует условия или правила типа IF, THEN. Он может быть записать как "ЕСЛИ
условие ТО решение". Мы можем создавать правила на основе наших требований на
этапе обучения [2]. \cite{article18}

\subsection{Методы, основанные на тональных словарях}

Подход на основе лексикона далее подразделяется на подход на основе словаря и
подход на основе корпуса. Подход на основе словаря находит исходные слова, а
затем ищет в словаре их синонимов и антонимов.\cite{article2}

В этом подходе, прежде всего, вручную собирается небольшой набор слов
настроения, которые известны как "seed words", с их известной положительной или
отрицательной ориентацией. Затем этот набор увеличивается путем поиска их
синонимов и антонимов в WordNet или другом онлайн-словаре.  Новые слова
добавляются к существующему списку. Затем запускается следующая итерация.
Итерация должна быть остановлена, если не найдено ни одного нового слова.
Наконец, для очистки списка используется набор ручной проверки \cite{article4}.

В этом подходе, прежде всего, вручную собирается небольшой набор слов
настроения, которые известны как "seed words", с их известной положительной или
отрицательной ориентацией. Затем этот набор увеличивается путем поиска их
синонимов и антонимов в WordNet или другом онлайн-словаре. Новые слова
добавляются к существующему списку. Затем начинается следующая итерация.
Итерация должна быть остановлена, если не найдено ни одного нового слова.
Наконец, для очистки списка используется набор ручной проверки. В [18] в
качестве словаря используется Wordnet. Автор использует обзоры мобильных
телефонов с сайта Amazon. Они вводятся в систему. Полярность вычисляется на
основе большинства слов мнения. Экспериментальные результаты системы AIRC
Sentiment analyzer" сравниваются с предложенной системой, и предложенная система
обеспечивает лучшую точность. В будущем будут проведены некоторые
усовершенствования этой техники. Она будет работать с предложениями, содержащими
относительные клаузулы типа не только-но и также, а также с предложениями,
содержащими клаузулы ни-нор, ни-или и т.д.  В работе [19] предлагается система
поиска мнений на основе аспектов под названием "Aspect-based Sentiment
Orientation System", которая извлекает признаки и мнения из предложений и
определяет, являются ли данные предложения положительными, отрицательными или
нейтральными для каждого признака. Отрицание также обрабатывается системой. Для
определения семантической ориентации предложений используется метод словаря,
основанный на несамостоятельном подходе. Для определения слов мнения и их
синонимов и антонимов используется WordNet как словарь. Определяются все
характеристики продукта, по которым даются отзывы, и определяется ориентация
предложения по каждой характеристике. Полярность определяется на основе
большинства слов мнения. В итоге система генерирует краткое описание
положительных, отрицательных и нейтральных предложений, которые пользователям
будет легче читать, анализировать и принимать решение о том, стоит ли покупать
данный продукт. или нет. \cite{article4}

Данный подход основан на использовании словарей с заранее подготовленными
вручную шаблонами эмоционально важных слов и словосочетаний с их эмоциональными
оценками. При использовании данного подхода в тексте ищутся пересечения со
словарем. Затем по сумме оценок найденных пересечений определяется тональность
заданного текста. Данный подход показывает хорошие результаты для некоторых
областей. Основной недостаток данного подхода в большой сложности подготовки
словарей, надо хорошо знать предметную область, для которой составляется
словарь. Второй недостаток — это плохая масштабируемость, нельзя использовать
один и тот же словарь для разных предметных областей. Одинаковые термины в
различных областях могут вносить разный вес в степень эмоциональной окраски
\cite{article9}

Первый лингвистический метод основан на тональных словарях. Тональный словарь
представляет собой набор слов или биграмм, которым задается определенный вес
принадлежности к позитивному или негативному классу. При анализе текста каждое
слово ищется в этом словаре, и его вес записывается. Если слова нет в словаре,
то его класс считается нейтральным, и вес равняется нулю. После того как все
веса получены, высчитывается принадлежность данного текста к определенному
классу тональности \cite{article14}.

Подход на основе словаря. При словарном подходе некоторые слова выбираются в
качестве начального слова, и эти слова используются для поиска синонимов, чтобы
увеличить размер набора слов. Для увеличения размера используются
онлайн-словари. Исходные слова - это слова мнения, которые являются уникальными
и важными в корпусе \cite{article16}.

Подход на основе словаря - В этой системе пользователь собирает набор слов,
которые выражают чувства, и составляет список семян. После этого пользователь
начинает поиск в разговорниках и лексиконе, чтобы найти синонимы и антонимы
конкретного текста. После этого вновь созданные заменители добавляются в список.
пока не будет найдено ни одного нового слова. пользователей, этот процесс
продолжается.  Недостатки: Приходится бороться за поиск контекстных или
ориентированных на область эмоций слов. \cite{article18}


\subsection{Методы, основанные на корпусах}

Подход, основанный на корпусе, начинает с исходного списка слов, выражающих
мнение, а затем находит другие слова, выражающие мнение, в большом корпусе,
чтобы помочь найти слова, выражающие мнение, с контекстно-специфической
ориентации \cite{article2}.

Подход на основе корпуса. В подходе, основанном на корпусе, мы не только находим
метку слова, но и ориентируемся на контекст. В этом подходе сначала составляется
список исходных слов, а затем синтаксическая модель этих слов используется для
генерации новых субъективных слов из корпуса. Синтаксический паттерн означает
слово, которое встречается друг с другом или вместе. Этот подход работает в двух
направлениях:
- Статистический подход.
- Семантический подход.
Автор [23] продемонстрировал оба подхода на основе лексикона. Он заметил, что
подход на основе корпусов с SVM обеспечивает высокую точность для данных с
легкой структурой. Он также заявил, что с увеличением количества лексики
точность подхода на основе лексики также увеличивается.\cite{article16}

Корпус - это, по сути, термин, который является кластером письменных текстов,
как группа некоторых письменных текстов, часто по очень точному вопросу. В этом
случае пользователи используют корпус текстов для составления списка семян,
который находится в организованной ситуации \cite{article18}.


\section{Методы машинного обучения}

В этом подходе первоначально классификация выполняется путем взятия двух
различных сборок документа. Обученные данные и тестовые данные являются их
частью. Это называется непроизвольной классификация. Далее текст извлекается из
характеристик и классифицируется на I) контролируемый и II) неконтролируемый.
\cite{article18}

\subsection{Наивный байесовский классификатор}

Наивный Байес NB: контролируемый вероятностный подход, который может предсказать
распределение вероятности по множеству классов, учитывая наблюдение на входе, а
не только вывести наиболее вероятный класс, к которому должно принадлежать
наблюдение. Вероятностные классификаторы обеспечивают ценную классификацию как
отдельный классификатор или в сочетании с другими классификаторами в ансамбли.
NB широко используется для классификации текстов. Он основан на теореме
вероятности Байеса, в которой вычисляется апостериорная вероятность класса или
заданного предиктора.  Алгоритм NB используется примерно в 31 из 157 (около
20\%) исследованных статей. Например, в [29] достигнуто Acc от 88,0\% до 99.89\%
для различных используемых наборов данных, в то время как Acc 0,7, R 0,35, Pr
0,47 были получены для арабских твитов SA в статье [63]. [63]. В [80] английский
SA с использованием POS-функций и классификатора MNB дает Acc от 74\% Pr от
77\%R74\% F1 от 74\%. \cite{article2}

Классификатор Naive Bayes является самым простым и наиболее используемым
классификатором. Наивный Байес вычисляет последующую вероятность класса,
основываясь на распределении слов в документе. Модель работает с извлечением BOW
признаков, которые игнорирует положение слова в документе. Используйте теорему
Байеса для прогнозирования вероятность того, что данный набор характеристик
принадлежит определенной метке.
Система, предложенная в [6], извлекает аспекты в отзывах покупателей о товарах.
Из каждого предложения отзыва извлекаются существительные и номинальные фразы.
Минимальный порог поддержки используется для поиска всех частых аспектов в
приведенных предложениях обзора. Алгоритм Naive Bayesian, использующий
контролируемый подход, основанный на подсчете терминов, применяется для
определения того, является ли предложение положительным или отрицательным
мнением, а также определяет номер предложения. В статье [12] представлен метод
анализа чувств, вызванных рецензиями пользователей на фильмы. Классификация
рецензий на положительные и отрицательные классы основана на алгоритме наивного
Байеса. В качестве обучающих данных мы используем коллекцию (предварительно
классифицированных как положительные и отрицательные) предложений, взятых из
рецензий на фильмы. Для улучшения классификации мы исключили несущественные
слова и ввели их в группы классификации слов (n-граммы). Для n = 2 групп мы
добились существенного улучшения классификации. \cite{article4}

Наивный байесовский классификатор – является вероятностным классификатором.
Наивная байесовская модель вычисляет условную вероятность класса на основе
распределения слов в документе. Один из самых простых используемых
классификаторов. Основан на теореме Байеса с предположением о том, что все
признаки являются независимыми, благодаря чему и получил название наивный
байесовский классификатор [13]. Но обычно в текстовых документах, предположение
о независимости не подтверждается, что делает его слабоэффективным. Тем не менее
несмотря на всю простоту и ограничение на независимость, байесовский
классификатор может показывать хорошие результаты при классификации текста. В
данном исследовании с помощью наивного байесовского классификатора на различных
данных получают точность от 55\% до 79\% [21]. Одним из преимуществ является
малое количество данных необходимых для обучения и простота реализации [3].
\cite{article9}

Наивный Байес. Это вероятностный алгоритм классификации. Он рассматривает каждое
слово независимо, поскольку не учитывает местоположение термина в предложении.
Naïve Bayes основан на теореме Байеса для вычисления вероятности каждого
термина, соответствующего метке. 
%p(label|features) = p(label) ∗ p(features|label) p(features) (1) 
p(label) - это предварительная вероятность
метки в наборе данных. p(feature|label) - это предварительная вероятность
признака, связанного с меткой. p(feature) - это предварительная вероятность
признака, который встречается. Geol и др. [12] использовали лексикон
SentiWordNet вместе с Naïve Bayes, что улучшило классификацию набора данных
twitter, так как он обеспечивает оценку положительных и отрицательных твитов.
\cite{article16}

Наивный Байес: В этом случае, чтобы генерировать возможности группы, чтобы
обеспечить предсказание того, что группа свойств принадлежит к одной конкретной
метке с помощью теоремы Байеса, используя только текстовый документ в качестве
входных данных. BOW - Bag of Words - это способ извлечения текста с помощью
методологии машинного обучения, которая проста и легко реализуема. Эта
существующая модель проводит, что эти все признаки, которые даны автономно. [20]

P (label/features) =P (label)* P (features/label)/P (features)
\cite{article18}

\subsection{Логическая регрессия}

Логическая регрессия – является методом линейного классификатора, оценивающий
вероятность принадлежности объектов к классу путем сравнения с логической кривой
по значениям множества признаков. Используется как для задач регрессии, так и
для классификации.  На практике часто рассматривается логическая регрессия с
регуляризацией. Регуляризация заключается в том, что модель начинает штрафовать
за очень большие веса, что не дает модели переобучиться. Логическая регрессия
один из самых популярных методов классификации и обученная модель показывает
очень хорошие результаты. Из недостатков можно выделить, что необходима
качественная предобработка признаков и их отбор [14]. \cite{article9}

В нашем проекте для построения модели мы используем алгоритм логистической
регрессии. Он определяет вероятность наступления события путем подгонки данных к
функции logit. В алгоритме используется уравнение:

Здесь, Если log(p/(1-p)) больше нуля, то коэффициент успеха каждый раз
оказывается больше половины от 100 процентов.

F1-Score можно определить как среднее гармоническое от A и B. F1-Score 0.54
наблюдается для валидационного набора при использовании подхода Bag-of-words.
Теперь мы будем использовать подход TF-IDF для вычисления F1-Score для той же
модели и получим 0,558 для валидационного множества. В целом, рассматривая метод
TF IDF мы можем наблюдать увеличение результата валидации. Здесь A и B
представлены как точность и recall соответственно. \cite{article12}


В работе Sharma и Kaur (2015) авторы предлагают схему, основанную на
классификаторе логистической регрессии, для прогнозирования личности по данным
Twitter.  Как правило, регрессионные алгоритмы используются, когда целевой
атрибут не номинальный, а порядковый или непрерывным. Поэтому применение
регрессии можно найти в СА для задач определения полярности баллов (Drake,
%Ringger, & Ventura, 2008) или для того, чтобы определения доверительной оценки
%(Ertugrul, Onal, & Acarturk, 2017; Onal, Ertugrul, & Cakici, 2014).
\cite{article13}

\subsection{Метод максимума энтропии}

Классификатор максимальной энтропии (известный как условный экспоненциальный
классификатор) преобразует помеченные наборы признаков в векторы с помощью
кодирования. Этот закодированный вектор затем используется для расчета весов для
каждого признака, которые затем могут быть объединены для определения наиболее
вероятной метки для набора признаков. набора признаков. \cite{article4}

Метод максимума энтропии – также как и наивный байесовский классификатор
является вероятностным классификатором. Данный метод основан на принципе
максимальной энтропии, что наиболее характерным распределением вероятностей
неопределенной среды, являются распределения, которые максимизируют выбранную
меру неопределенности при заданной информации о поведении среды. В отличии от
наивного байесовского классификатора метод максимума энтропии не делает
предположения о независимости признаков, что позволяет добиться лучших
результатов. Также как и у наивного байесовского классификатора преимуществами
являются простота реализации и малое количество данных необходимых для обучения
[14]. \cite{article9}

c) Максимальная энтропия: В результате кодирования помеченные наборы признаков
преобразуются в векторы с помощью классификаторов. Эти векторы преобразуются и
используются для определения весов этих признаков, которые могут быть
использованы для предположения и предсказания метки для каждого из наборов
признаков. \cite{article18}

\subsection{k-ближайших соседей}

K-NN классифицирует новые объекты на основе атрибутов и обучающих образцов, где
результаты новых тестовых образцов классифицируются на основе большинства
категорий в K-NN. Алгоритм K-NN использует классификацию соседей в качестве
предсказательной ценности новой тестовой выборки.  При построении обучающих
данных обращается внимание на соотношение документов друг с другом.  Процедура
алгоритма KNN может быть объяснена следующим образом:

a. Вычислить расстояние между тестовыми данными и построенными обучающими
данными.  В качестве одного из уравнений при вычислении близости можно
использовать уравнение косинусного сходства.

b. Определить значение параметра k - количество ближайших соседей. В данной
работе значения k равны 1, 3, 5, 9 и 10. 

c. отсортировать наименьшие расстояния от данных выборки.

d. сопоставление категорий по совпадению. Найдите наибольшее число соседей.
Затем укажите категорию.  Расстояние, используемое в данной работе, - Cosine
Similarity.

\subsection{Деревья решений}

Классификатор дерева решений обеспечивает иерархическую декомпозицию
пространства обучающих данных, в котором условие используется в значении
атрибута для разделения данных. Условием или предикатом является наличие или
отсутствие одного или нескольких слов. Разделение пространства данных
выполняется рекурсивно до тех пор, пока узлы листьев не будут содержать
определенное минимальное количество записей, которые используются для
классификации. В [7] характеристики рецензий на фильмы, полученные из IMDB,
были извлечены с использованием обратной частоты документа и важности найденного
слова. Анализ главных компонент и CART были использованы для отбора
характеристик в соответствии с важностью произведения относительно всего
документа. Точность классификации, полученная с помощью LVQ, составила 75\%.
Исследование эмоциональных изменений в подростковом возрасте и причин этих
изменений с помощью методов интеллектуального анализа данных предложено в [11].
При классификации эмоций и использовании дерева решений анализируются различные
эмоциональные вариации. Также генерируются правила "если - то на основе дерева
решений. Анализ типичных значений используется для определения вариаций эмоций у
ребенка, который имеет определенный тип инвалидности. \cite{article4}

Деревья решений – представляют из себя древовидную структуру, где на ветках
записаны атрибуты, от которых зависит распределение вероятностей классов, а на
листьях значения вероятностей классов. Данный метод просто в интерпретации и
требует минимальной предобработки данных. Но сами по себе деревья решений
используются редко, так как они легко переобучаемы и слишком зависимы от
обучающих данных. При небольших изменениях в обучающей выборке мы получаем
кардинально разные результаты на тестовых данных. Чаще применяются ансамбли
решающих деревьев, которые решают данные проблемы. Примеры таких ансамблей:
случайный лес или градиентный бустинг [15]. \cite{article9}

Дерево решений. Это древовидная структура, в которой нетерминальные узлы
представляют признак, а терминальный узел - метку. Путь выбирается на основе
условия. Это рекурсивный процесс, который в конечном итоге приводит к
терминальному узлу, дающему метку на входе.
Основной проблемой в дереве решений является определение того, какой атрибут
должен быть выбран в качестве корневого узла. Эту задачу можно решить, используя
некоторые статистические методы, такие как прирост информации и индекс Джини.
Дерево решений - это хороший метод для анализа настроений, поскольку он дает
хороший результат на большом количестве данных. Часто используемыми алгоритмами
дерева решений являются CART, CHAID и C5.0. Дерево решений делит обучающие
данные иерархически. Для разделения данных используется используется условие,
которое находится на значении атрибута. Условие на основе того, присутствует ли
слово присутствует или отсутствует. Процесс деления продолжается до тех пор,
пока терминальные узлы представляют собой небольшое количество признаков,
которые используются для задачи классификации. Котенко и др. [18] использовали
дерево решений для блокировки ложного контента на веб-сайте. Он использовал
TF-IDF для взвешивания слова, которое говорит о важности слова, и биномиальный
классификатор. и биномиальный классификатор, который определяет, принадлежит ли
слово к определенной категории или нет (рис. 3) \cite{article16}

3 .Классификатор дерева решений: Чтобы разделить данные, существует есть
условие, которое используется. один класс состоит из тех данных которые
удовлетворяют условию, а другой класс состоит из остальные данные. Эта техника
называется рекурсивной техника состоит из двух частей: разделение по одному
признаку и разделение по нескольким признакам. разделение по одному признаку и
разделение по нескольким признакам. \cite{article18}

\subsection{Случайный лес}

Случайный лес – ансамбль решающих деревьев. В данном методе строиться очень
много решающих деревьев большой глубины на разных обучающих данных. Деревья
строятся до тех пор, пока в каждом листе не окажется очень мало объектов, то
есть они сильно переобучены.  Затем все деревья объединяются, и мы получаем
эффективный классификатор, у которого отсутствуют недостатки решающих деревьев.
Но это вызывает некоторые проблемы, если признаков очень много, то этот подход
работает не очень хорошо: деревья будут очень глубокими, на их построение будет
уходить слишком много времени. \cite{article9}

\subsection{Метод опорных векторов}

Классификаторы машин с опорными векторами (SVM): Этот метод машинного обучения
под наблюдением стремится определить линейные разделители в пространстве,
которые могут наилучшим образом разделить различные классы путем максимизации
маргинальной гиперплоскости (ММГ), что позволит минимизировать ошибку. Текстовые
данные идеально подходят для классификации SVM из-за разреженности текста.
Однако они, как правило, коррелируют друг с другом и обычно организованы в
линейно разделяемые категории[70]. SVM может построить нелинейную поверхность
принятия решений в исходном пространстве признаков путем нелинейного отображения
экземпляров данных в пространство внутренних произведений. Затем классы могут
быть разделены линейно с помощью гиперплоскости [71].  Примеры лучших
результатов работы SVM: в [72] SA итальянского языка достигает Acc 91,58\%, в то
время как в арабском [15] Acc 90\%, ABSA Acc 95.4\% в [14], а использование
оптимизации для FS в дополнение к SVM для SC повышает Acc 95,93\% в [19]. Acc
91,64\% в [73] для английского языка с использованием ансамбля SVM и NB,
английский язык SA Acc 91,67\% в [74]. \cite{article2}

Текстовые данные идеально подходят для SVM-классификации благодаря низкой
природе текста, в котором немногие признаки нерелевантны, но имеют тенденцию
коррелировать друг с другом и в целом организованы в линейно разделяемые
категории.
В [10] машинное обучение (SVM) в сочетании с лексикой, специфичной для данной
области, применяется для классификации аспектов и определения полярности отзыва
о продукте. SVM обучается для моделирования классификации аспектов, и эта
обученная SVM используется для классификации полярности по аспектам. Результаты
экспериментов показывают, что предложенные методы достигли точности около 78\%.
Данные веб-публикаций применяются к подсистеме извлечения эмоциональных причин и
комбинируется метод отбора комплиментарных характеристик, основанный на
результатах этих характеристик. В процессе обучения веб-публикации с
неизвестными эмоциями публикуются в модели классификации SVM и SVR, и результат
дает информацию о типе эмоции [13]. \cite{article4}

Метод опорных векторов (SVM) – набор линейных алгоритмов машинного обучения для
задач регрессии и классификации. Цель метода заключается в нахождении среди всех
возможных гиперплоскостей пространства, отделяющих два класса обучающих примеров
друг от друга, такойгиперплоскости, расстояния от которой до ближайших векторов
обоих классов равны (оптимальная разделяющая гиперплоскость) [16]. Является
одним из наиболее эффективных методов классификации. Данный метод часто
применяется в задачах классификации текстов и показывает хорошие результаты
[17]. Линейные модели хорошо масштабируются, могут работать с большим
количеством признаков, на очень больших выборках. \cite{article9}

Машина опорных векторов (SVM). SVM впервые инициализируется для решения задач
бинарной классификации. Она фокусируется на определении наилучших
гиперплоскостей, которые действуют как разделитель для описания границ принятия
решения между точками данных, которые относятся к разным классам. Необходимо
выбрать гиперплоскость, которая может поддерживать максимальное расстояние между
двумя опорными векторами разных классов, как показано на рисунке. SVM способна
решать задачи линейной и нелинейной классификации. Зайнуддин и Селамат [14]
использовали SVM для классификации с различными схемами взвешивания, такими как
TF-IDF, встречаемость термина, двоичная встречаемость. Он использует хи-квадрат
в качестве выбора признака, который применяется для уменьшения размерности и
удаления шума. С помощью эксперимента он показал, что использование выбора
признаков по критерию хи-квадрат с SVM повышает точность. \cite{article16}

Линейный классификатор
A) Машина опорных векторов (SVM): Эта модель обучения находится под наблюдением
и используется для классификации. Наиболее важная цель этой конкретной модели -
убедиться, что это лучший линейный разделитель для классификации. Это позволит
создать модель, в результате которой новая информация будет отнесена к одному
или двум классам с помощью обучения SVM.  \cite{article18}

\subsection{Нейронные сети}

Конволюционные нейронные сети (КНС): CNN представляют собой модификации НС с
прямой передачей данных, обладающие следующими свойствами: (i) сверточные слои:
CNN обычно имеет один или несколько сверточных слоев, которые строят смежные
локальные признаки (скрытые единицы); (ii) разреженная связность: вместо
полностью связанных нейронов, входы скрытых единиц в слое l поступают от
подмножества единиц в слое l-1, которые имеют смежные локальные признаки; (iii)
общие веса: Единицы, принадлежащие к одним и тем же локальным признакам, имеют
одинаковые веса (весовой вектор и смещение); и (iv) объединение: вместо того,
чтобы использовать все локальные признаки на следующем уровне, они имеют
объединяющий слой, который вычисляет либо среднее, либо минимум, либо максимум
этих признаков. Для задач НЛП конволюционные слои выделяют локальные признаки
вокруг окна заданной последовательности слов. Кроме того, их часто собирают для
извлечения характеристик более высокого уровня [75]. 36 из 157 статей (23\%)
использовали CNN в SC. Испанская ABSA получила Acc 70,5 \% в [46], SA для тайских
детских историй достигает F1- score 81,7 \% при использовании CNN в [76], Acc
89,5 \% в арабском алжирском диалекте SA при использовании CNN в [16], китайская
SA в [77]получила 92,52 \% Acc, короткая текстовая SA [135]получила Acc 0,92
Micro-AUC 0,98 Macro-AUC0,9,7. \cite{article2}

Длительная кратковременная память LSTM: Искусственная нейронная сеть (ИНС),
содержащая прямые циклы в своих скрытых связях, является рекуррентной нейронной
сетью (РНС). RNN может обрабатывать только конечное число
последовательностей[78] из-за уменьшающегося градиента; сети с долговременной
памятью (LSTM) являются разновидностью RNN с ячейкой памяти, которая может
сохранять состояния в течение длительных периодов времени, преодолевая проблему
зависимостей на больших расстояниях в RNN [79]. LSTM - это ячейка памяти, ct,
которая рекуррентно связана сама с собой. Она выполняет умножение с помощью трех
компонентов: входного гейта it, гейта забывания ft и выходного гейта ot. Эти
управляющие векторы имеют диапазон [0, 1]. Ячейка делает сознательный выбор
относительно хранения памяти и времени доступа к блокам с помощью открытых и
закрытых ворот. Рисунок 5 показывает, что LSTM и двунаправленные LSTM (BiLSTM)
использовались в СК в 40 из 157 публикаций (около 25\%) в обеих базах данных.
\cite{article2}

Нейронная сеть состоит из множества нейронов, где нейрон является ее основной
единицей. Входы нейронов обозначаются вектором на линии Xi, который является
частотой слов в ith документе. Существует набор весов, которые ассоциируются с
каждым нейроном, используемым для вычисления функции его входов. На основе
входов и весов формируется выход. \cite{article4}

b. Байесовская сеть
Основным предположением классификатора NB является независимость характеристик.
Другим крайним предположением является предположение о том, что все
характеристики являются зависимыми. Это приводит к модели Байесовской сети,
которая представляет собой направленный ациклический граф, узлы которого
представляют случайные переменные, а ребра - условные зависимости. BN считается
полной модель для переменных и их взаимосвязей. При добыче текста сложность
вычисления BN является очень дорогой, поэтому она используется нечасто.
\cite{article4}

Сверточные нейронные сети (CNN). Изначально сверточные сети начали использовать
для распознавания изображений, но после большого успеха в области компьютерного
зрения, их стали пробовать применять и в других областях. В частности, их стали
использовать для решения задач классификации текстов. В сверточных нейронных
сетях используется операция свертки, когда каждый фрагмент данных умножается на
матрицу (ядро) свертки поэлементно, после чего результат суммируется и
записывается в аналогичную позицию выходных данных. Поскольку свертки происходят
на соседних словах, модель может уловить отрицания или n-граммы, которые несут
новую информацию о настроении. В данном исследовании показано, что сверточные
сети могут демонстрировать высокие результаты при анализе тональности текста,
превосходя другие алгоритмы на некоторых тестах [19]. \cite{article9}

Рекуррентные нейронные сети (RNN) широко распространены в задачах обработки
текста, в том числе и для анализа тональности. Особенности рекуррентных
нейронных сетей — это наличие обратных связей, связь от более удаленного
элемента к менее удаленному. Это позволяет запоминать и воспроизводить
последовательности реакций на один стимул. Значение весов сети зависит как от
текущих, так и от предыдущих входных данных, благодаря чему вес каждого слова
влияет на веса остальных слоев в предложении [6].
GRU (Gated Recurrent Unit – управляемые рекуррентные нейроны) и LSTM (Long
Short- Term Memory – длительная кратковременная память) являются модификациями
рекуррентных нейронных сетей. Они решают проблему исчезающего градиента, которой
подвержена рекуррентная нейронная сеть.
Рекуррентные нейронные сети показывают наилучшие результаты во многих задачах,
но процедура их обучения достаточно трудоемка [7]. \cite{article9}

Байесовская сеть. Поскольку классификатор Наива Байеса рассматривает каждое
слово как независимое, он не может найти семантическую связь между словами, в то
время как Байесовская сеть может. Сеть Байеса учитывает зависимость слов друг от
друга. Сеть Байеса представляет зависимость в виде направленного графа, который
является ациклическим, где каждый узел представляет слово как переменную, а
ребра представляют зависимость между переменными. В качестве классификатора
настроений Аль-Смади и др. [13] использовали байесовские сети, обнаружив
конкурентоспособный результат, а иногда и высокий, по сравнению с другими
классификаторами. \cite{article16}

\section{Гибридные}

Существуют также гибридные методы, объединяющие в себе несколько различных
методов.  В работе [20] для задачи классификации текста использовался гибридный
метод, объединяющий тональные словари и метод опорных векторов.  В статье [21]
авторы для решения задачи сентимент-анализа объединяли CNN и k-ближайших
соседей. \cite{article14}

Третий - гибридные подходы, которые объединяют подходы, основанные на правилах и
машинном обучении.Например, Кумар и коллеги разработали гибридную систему
анализа настроений персидского языка, которая объединила лингвистические правила
и модули CNN и LSTM для классификации настроений [46]. Мескеле и Фрасинкар
предложили гибридную модель для аспектного анализа настроений ALDONAr, которая
объединяет онтологию домена настроений для сбора информации о домене, BERT для
получения вкраплений слов и два слоя CNN для улучшения классификации настроений
[47]. Модель достигла точности 83,8\% и 87,1\% на наборах данных SenEval 2015
Task 12 [48] и SemEval 2016 Task 5 [49] соответственно. Подобно подходам,
основанным на правилах, языковые модели широко используются в гибридных подходах
[50]-[52].  С одной стороны, сочетание сильных сторон подходов на основе правил
и машинного обучения обычно позволяет получить более точные результаты. С другой
стороны, как следствие комбинации, гибридные подходы также получают проблемы и
ограничения подходов, основанных на правилах и машинном обучении.
подходов.\cite{article15}

Искусственная нейронная сеть. Искусственная нейронная сеть (ИНС) имитирует
структуру нейронов человеческого мозга. Основной единицей нейронной сети
является нейрон. ИНС состоит из входного слоя, скрытого слоя и выходного слоя.
На вход нейрону подается вектор "a (i)", вектор обозначает частоту слова в
документе. Существует вес "A", соответствующий каждому нейрону, который
используется для вычисления функции.  Нейронная сеть использует линейную функцию
x (i) = A. (a (i)). Знак x (i) используется для классификации класса.  В
искусственных нейронных сетях обучение модели состоит из двух этапов: прямое
распространение и обратное распространение. При прямом распространении входные
данные подаются на входной слой нейронов, которые умножаются на веса,
представляющие собой случайные числа. Функции используются для нормализации
выходного значения между 0 и 1. Затем выходное значение сравнивается с целевым
значением, если между двумя значениями есть разница (ошибка), то выполняется
обратное распространение. Во время обратного распространения вход умножается на
значение ошибки, таким образом, вес может быть скорректирован. Таким образом,
обучение зависит от ошибки. Автор [15] использовал нейронную сеть для
классификации лиц, что дало обеспечила высокую точность.  Вега и Мендес-Васкес
[16] предложили динамическую нейронную сеть (DNN). Модель, в которой он
использовал конкурентное и хеббианское обучение для процесса обучения.  Он
сравнил базовый подход с DNN и показал, что DNN работает лучше. лучше, чем
базовые методы. Патил и другие [17] предложили метод, в котором Он использовал
латентный семантический анализ (LSA) со сверточной нейронной сетью (CNN).  LSA -
это метод преобразования слова в вектор. Взвешивание в LSA выполняется с помощью
алгоритм TF-IDF. Его модель обеспечивает точность 87\%. \cite{article16}

б) Байесовская сеть: Она используется для проявления взаимосвязей между
различными признаками. Ее можно сравнить с ациклическим графом, в котором узлы
представляют случайную переменную, а ребра - зависимости. представляют
зависимости Эта модель очень дорогостоящая и поэтому она практически не
используется \cite{article18}


B) Нейронная сеть (NN): Это нейронная структура мозга, имеющая электронные сети
нейронов. В этой сети нейрон является основным компонентом. Нейроны делятся на
три части - входную, скрытую и выходную \cite{article18}
